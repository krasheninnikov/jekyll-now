---
layout: page
title: About
permalink: /about/
---
I am a Research Software Engineer working on a deep RL and robotics at Sony AI. I completed my masters in AI at the University of Amsterdam, and had a pleasure to work with UC Berkeley's Center for Human-Compatible AI during and after the masters. Next, I'll be starting a PhD at the University of Cambridge, where I'll work on technical AGI safety with David Krueger.


<!---Last fall I graduated cum laude with a MSc in AI from the University of Amsterdam, which I was able to attend thanks to a $63k grant from the Open Philanthropy Project. During and after the masters I had the pleasure to work with UC Berkeley's Center for Human-Compatible AI; this collaboration resulted in two papers. Next, I am joining Sony AI in Zurich starting September 2020.->


<!---I am a second year MSc artificial intelligence student at the University of Amsterdam. These days I am focused on figuring out how an AI can robustly infer what humans want from what they do. --->

<!--- My CV can be found <a href="https://drive.google.com/file/d/1jrgyABLuj5B2oup__32KymF0xt72iEVD/view?usp=sharing">here</a>.

<!--- In my spare time, I enjoy hiking, bouldering, listening to podcasts and meditating.  --->

# Publications

<i>Preferences implicit in the state of the world.</i> Rohin Shah*, <b>Dmitrii Krasheninnikov*</b>, Jordan Alexander, Anca Dragan, Pieter Abbeel. International Conference on Learning Representations (ICLR) 2019. <a href="https://openreview.net/forum?id=rkevMnRqYQ">Paper</a>, <a href="https://bair.berkeley.edu/blog/2019/02/11/learning_preferences/">blog post</a>, <a href="https://github.com/HumanCompatibleAI/rlsp/blob/master/poster-preferences-implicit-in-the-state-of-the-world.pdf">ICLR 2019 poster</a>, <a href="https://github.com/HumanCompatibleAI/rlsp">code</a>.

<i>Combining reward information from multiple sources.</i> <b>Dmitrii Krasheninnikov</b>, Rohin Shah, Herke van Hoof. Learning with Rich Experience and Safety & Robustness in Decision Making workshops at NeurIPS 2019. <a href="https://arxiv.org/abs/2103.12142">Paper</a>, <a href="https://drive.google.com/open?id=1oPG1nfjnVge0Pi0JJYi7x78IGQIeeR2s">poster</a>.

<i>Benefits of Assistance over Reward Learning.</i> Rohin Shah, Pedro Freire, Neel Alex, Rachel Freedman, <b>Dmitrii Krasheninnikov,</b> Lawrence Chan, Michael Dennis, Pieter Abbeel, Anca Dragan, Stuart Russell. Best paper award at the Cooperative AI workshop at NeurIPS 2020. <a href="https://openreview.net/forum?id=DFIoGDZejIB">Paper</a>.

\* Equal contribution
