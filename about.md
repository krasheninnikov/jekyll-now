---
layout: page
title: About
permalink: /about/
---
This fall I graduated cum laude with a MSc in AI from the University of Amsterdam, which I was able to attend thanks to a $63k <a href="https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/ai-scholarships-2018">grant</a> from the Open Philanthropy project. During the masters I had the pleasure to intern at the Center for Human-Compatible AI at UC Berkeley; this collaboration resulted in two papers. At the moment I am figuring out the next step in my career.


<!---I am a second year MSc artificial intelligence student at the University of Amsterdam. These days I am focused on figuring out how an AI can robustly infer what humans want from what they do. --->

<!--- My CV can be found <a href="https://drive.google.com/file/d/1jrgyABLuj5B2oup__32KymF0xt72iEVD/view?usp=sharing">here</a>.

<!--- In my spare time, I enjoy hiking, bouldering, listening to podcasts and meditating.  --->

# Publications

Rohin Shah*, <b>Dmitrii Krasheninnikov*</b>, Jordan Alexander, Anca Dragan, Pieter Abbeel. <i>Preferences implicit in the state of the world.</i> International Conference on Learning Representations (ICLR) 2019. <a href="https://openreview.net/forum?id=rkevMnRqYQ">Paper</a>, <a href="https://bair.berkeley.edu/blog/2019/02/11/learning_preferences/">blog post</a>, <a href="https://github.com/HumanCompatibleAI/rlsp/blob/master/poster-preferences-implicit-in-the-state-of-the-world.pdf">ICLR 2019 poster</a>, <a href="https://github.com/HumanCompatibleAI/rlsp">code</a>.

<b>Dmitrii Krasheninnikov</b>, Rohin Shah, Herke van Hoof. <i>Combining reward information from multiple sources.</i> Learning with Rich Experience and Safety & Robustness in Decision Making workshops at NeurIPS 2019. <a href="https://drive.google.com/file/d/1dBDqdCU_6ZZJen_8lZCn-RHtO7dB1QKG/view?usp=sharing">Paper</a>, <a href="https://drive.google.com/open?id=1oPG1nfjnVge0Pi0JJYi7x78IGQIeeR2s">poster</a>.
